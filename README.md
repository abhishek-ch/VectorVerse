# ðŸŽ­ VectorVerse
## â’¸ Unveiling Vector Databases & LLM Models

VectorVerse is an exploratory platform that serves as a hub for exploring the output of various Vector Databases. With VectorVerse, you have the opportunity to delve into the results produced by multiple Vector Databases. Additionally, you can utilize VectorVerse to compare the output generated by multiple Language Model (LLM) Models, including private models. This enables you to gain valuable insights and make informed decisions based on a comprehensive analysis of different data sources and models.

<br/>


https://github.com/abhishek-ch/VectorVerse/assets/7579608/40d419e1-4834-447b-b7c9-27c739451a5e


## Key Features ðŸŽ¯
* __Multiple Vector Databases__: VectorVerse let you explore multiple Vector Databases are compare/observe the result.
* __LLM Model__: VectorVerse allows you to explore multiple LLM models output like GPT3, GPT4, GPT4All etc.
* Chat History is maintained using __sqlite__

## Current Support

### Vector Databases Support
1. [Qdrant](https://qdrant.tech/)
2. [Chroma DB](https://www.trychroma.com/)
3. [Elasticsearch](https://vector.dev/docs/reference/configuration/sinks/elasticsearch/)
4. [Redis](https://redis.io/docs/stack/search/reference/vectors/)
5. [FAISS](https://engineering.fb.com/2017/03/29/data-infrastructure/faiss-a-library-for-efficient-similarity-search/)

Current LLM Models Support
1. GPT3
2. GPT4
3. GPT4All
4. LLama

## ðŸŒµ Environment Setup

Create a .env file (template provided as example.env) and update the following

Then, download the LLM model and place it in a directory of your choice:
- LLM: default to [ggml-gpt4all-j-v1.3-groovy.bin](https://gpt4all.io/models/ggml-gpt4all-j-v1.3-groovy.bin). If you prefer a different GPT4All-J compatible model, just download it and reference it in your `.env` file.

```
openai_key=****
endpoint_url=***
api_type=azure
api_version=2023-03-15-preview
MODEL_TYPE=supports LlamaCpp or GPT4All
LLAMA_EMBEDDINGS_MODEL=/path/to/ggml-model-q4_0.bin
MODEL_PATH=/path/to/ggml-gpt4all-j-v1.3-groovy.bin
db_persistent_path=is the folder you want your vectorstore in
collection_name=examples
pdf_uploadpath=OPTIONAL
```

Note: because of the way `langchain` loads the `SentenceTransformers` embeddings, the first time you run the script it will require internet connection to download the embeddings model itself.

## ðŸ’¾ Installation

### Docker

Run `docker-compose up` and browse http://localhost:8501

### From Project

1. Git clone the project
2. Navigate to the directory where the repository was downloaded

    ```bash
    cd vectorverse
    ```
3. Install the required dependencies

    ```bash
    pip install -r requirements.txt
    ```

4. Run `run_es.sh`, `run_pg.sh` & `run_redis.sh` or set up your own
4. Run the project and access the url http://localhost:8501

    ```
    python -m verse
    ```

## â›„ Optional (If using OpenAI)
Configure OpenAI Key
    * If Using OpenAI key, simply `export OPENAI_API_KEY=*****`
    * If want to use config file, rename `config_template.ini` -> `config.ini` file inside the `database_agent` dir & update either Azure or OpenAI config

    By completing these steps, you have properly configured the API Keys for your project.

## Prerequisites Installation

* Redis Stack Server
* ElasticSearch 

_Or use `docker-compose.yml` provided with the code_
 

### Run the Tool
0. Check out the project and go the project root dir `VectorVerse`

1. If Redis/ES not preinstalled
```docker
docker compose up
```

2. Launch the app
```python
python -m verse
```

## References
1. Powered by Langchain
2. Uploader Inspired by Quivr